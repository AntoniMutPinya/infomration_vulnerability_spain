
### DATA & PACKAGES

source('A_Data_&_Packages.R')

################################################################################
### INDEPENDENT VARIABLE (X)
################################################################################


# The code above is designed to calculate the Information Vulnerability Index (IV), 
# which serves as an independent variable for further analysis. 
# The script processes data related to financial literacy, basic numeracy, 
# literacy skills, and the ability to read graphs, then uses Item Response Theory (IRT) 
# models to estimate a numerical index. This IV represents the vulnerability level 
# of individuals based on their responses to these questions. 
# Additionally, Min-Max scaling and normalization are applied to ensure the 
# values fall within a standard range, making the IV suitable for various analyses.

# Min-Max scaling function for variables.
min_max_scale <- function(x) {
  min_range <- 0
  max_range <- 1
  min_x <- min(x)
  max_x <- max(x)
  min_range + ((x - min_x) / (max_x - min_x)) * (max_range - min_range)
}


create_df_Answers <- function(ecf_2016) {
  
  # Create the data frame using conditional logic for Financial Literacy, 
  # Basic Numeracy, and Reading Graphs.
  df_Answers <- data.frame(
    
    # Financial Literacy
    FL1 = ifelse(ecf_2016$e0600 == 3, 1, 0),
    FL2 = ifelse(ecf_2016$e0700 == 0, 1, 0),
    FL3 = ifelse(ecf_2016$e0800 == 102, 1, 0),
    FL4 = ifelse(ecf_2016$e0900 == 1, 1, 0),
    FL5 = ifelse(ecf_2016$e1001 == 1, 1, 0),
    FL6 = ifelse(ecf_2016$e1002 == 1, 1, 0),
    FL7 = ifelse(ecf_2016$e1003 == 1, 1, 0),
    FL8 = ifelse(ecf_2016$e1200 == 1, 1, 0),
    
    # Basic Numeracy and Literacy
    NL1 = ifelse(ecf_2016$e0500 == 200, 1, 0),
    NL2 = ifelse(ecf_2016$e1101 == 1, 1, 0),
    NL3 = ifelse(ecf_2016$e1102 == 3, 1, 0),
    NL4 = ifelse(ecf_2016$e0401 == 3, 1, 0),
    NL5 = ifelse(ecf_2016$e0402 == 18, 1, 0),
    NL6 = ifelse(ecf_2016$e0403 == 2, 1, 0),
    NL7 = ifelse(ecf_2016$e0300 == 5, 1, 0),
    
    # Reading Graphs
    e0200a = ifelse(ecf_2016$e0200a == 1, 0.2, 0),
    e0200b = ifelse(ecf_2016$e0200b == 1, 0.2, 0),
    e0200c = ifelse(ecf_2016$e0200c == 0, 0.2, 0),
    e0200d = ifelse(ecf_2016$e0200d == 0, 0.2, 0),
    e0200e = ifelse(ecf_2016$e0200e == 0, 0.2, 0),
    
    # Filter
    filter = ecf_2016$b0600
    
  )
  
  # Summation for NL variables (graph reading)
  df_Answers$NL8 <- df_Answers$e0200a + df_Answers$e0200b + df_Answers$e0200c + 
    df_Answers$e0200d + df_Answers$e0200e
  
  # Remove duplicated variables
  df_Answers <- df_Answers[, !colnames(df_Answers) %in% c("e0200a", 
                                                          "e0200b", 
                                                          "e0200c", 
                                                          "e0200d", 
                                                          "e0200e")]
  
  df_Answers <- df_Answers[df_Answers$filter != -98, ]
  return(df_Answers)
}


# Function to fit a 3PL model and calculate the numerical index
create_index <- function(df_Answers, unimodel = 'F1 = 1-16') {
  
  # Select columns that start with "FL" from df_Answers
  columns_FL <- grep("^FL|NL", names(df_Answers), value = TRUE)
  
  df_FL <- df_Answers[, columns_FL]
  
  # Fit the 2PL model using the mirt function
  fit2PL <- mirt(data = df_FL, 
                 model = unimodel,  
                 itemtype = "2PL", 
                 verbose = FALSE)
  
  # Get the estimated scores (theta)
  IV <- fscores(fit2PL)
  
  return(IV)
}


# Usage
df_Answers <- create_df_Answers(ecf_2016)

IV <- min_max_scale(create_index(df_Answers))
IV <- as.data.frame(IV)
IV <- IV$F1

# Clean memory
rm(df_Answers, create_df_Answers, create_index)


################################################################################
### DEPENDENT VARIABLE (Y)
################################################################################


# The code above calculates dependent variable DV1 from the dataset (ecf_2016). 
# The code processes specific variables and transforms them based on various conditions. 
# It performs binary transformations, handles missing data, and calculates summary columns. 
# These dependent variables can then be used for further analysis or modeling. 


# Select column 'b0600' from ecf_2016 and create DV1
DV1 <- ecf_2016 %>% select(b0600)
# Replace values in DV1 that are less than 0 with NaN (to handle missing data)
DV1 <- ifelse(DV1$b0600 == -98, NaN, DV1$b0600)
# Set any values greater than 1 to 0 (binary transformation)
DV1 <- ifelse(DV1 != 1, 0, 1)
DV1 <- na.omit(DV1)


################################################################################
### CONTROL VARIABLES
################################################################################


# This R script is designed to perform a Principal Component Analysis (PCA) with 
# four components using various sociodemographic variables from the ecf_2016 dataset. 
# The PCA results will be used as control variables in subsequent regression models. 
# The script also includes plotting and analysis of factor loadings, as well as 
# the implementation of a regression model (logistic regression) to examine 
# relationships between dependent and independent variables while adjusting for PCA components.

# Step 1: Data Preparation
# Create a data frame (BE) using the ecf_2016 dataset, selecting specific questions (Q1 to Q12).
# Negative values are replaced with 0 for all selected variables.

BE <- data.frame(
  Filter = ecf_2016$b0600,
  Q1 = ifelse(ecf_2016$d0101 > 0, ecf_2016$d0101, 0),
  Q2 = ifelse(ecf_2016$d0102 > 0, ecf_2016$d0102, 0),
  Q3 = ifelse(ecf_2016$d0103 > 0, ecf_2016$d0103, 0),
  Q4 = ifelse(ecf_2016$d0104 > 0, ecf_2016$d0104, 0),
  Q5 = ifelse(ecf_2016$d0105 > 0, ecf_2016$d0105, 0),
  Q6 = ifelse(ecf_2016$d0106 > 0, ecf_2016$d0106, 0),
  Q7 = ifelse(ecf_2016$d0107 > 0, ecf_2016$d0107, 0),
  Q8 = ifelse(ecf_2016$d0108 > 0, ecf_2016$d0108, 0),
  Q9 = ifelse(ecf_2016$d0109 > 0, ecf_2016$d0109, 0),
  Q10 = ifelse(ecf_2016$d0110 > 0, ecf_2016$d0110, 0),
  Q11 = ifelse(ecf_2016$d0111 > 0, ecf_2016$d0111, 0),
  Q12 = ifelse(ecf_2016$d0112 > 0, ecf_2016$d0112, 0)
)

BE <- BE[BE$Filter != -98, ]

# Step 2: PCA Preparation
# Compute the polychoric correlation matrix.
mat_cor <- hetcor(BE)$correlations

# Perform Bartlett’s test to check the sphericity of the correlation matrix.
bartlett_test <- cortest.bartlett(mat_cor)

# Step 3: Factor Analysis (PCA)
# Perform PCA with 4 components using factor analysis (minres method).
fa_FL <- fa(BE, nfactors = 4, rotate = 'none', fm = 'pa', max.iter = 1, scores = "Bartlett")
df_Inst <- as.data.frame(fa_FL$scores)  # Save the factor scores

# Step 4: Create a DataFrame with Scaled Factor Scores
# Apply Min-Max scaling to factor scores.
min_max_scale <- function(x) {
  min_range <- 0
  max_range <- 1
  min_x <- min(x)
  max_x <- max(x)
  min_range + ((x - min_x) / (max_x - min_x)) * (max_range - min_range)
}

I1 <- min_max_scale(df_Inst$PA1)
I2 <- min_max_scale(df_Inst$PA2)
I3 <- min_max_scale(df_Inst$PA3)
I4 <- min_max_scale(df_Inst$PA4)

# Clean up by removing temporary variables.
rm(fa_FL, mat_cor, df_Inst, BE, bartlett_test)


################################################################################
### INSTRUMENTAL VARIABLES
################################################################################

# This script is used to create the instruments (IVs) that will be utilized in regression models. 
# These instruments are constructed based on specific variables from the ecf_2016 dataset, 
# including binary indicators and direct assignments. These IVs will help address endogeneity or omitted variable biases in the regressions. 
# Each instrument is based on conditional logic or directly sourced from the dataset to form relevant control variables for the models.


# Proxy of parent’s cultural level measured throw the number of books that 
# were present in the family house during the childhood of the individual

# IV_1: Binary indicator for a1400
# Set to 1 if a1400 is greater than or equal to 4, otherwise 0
InsV_1 <- ifelse(ecf_2016$a1400 >= 4, 1, 0)


# The predominant content of the university qualification requires or certain 
# mathematical baggage or financial general knowledge (engineering and technology, 
# health sciences, economics, management, business, legal sciences, or experimental sciences.).

# IV_2: Binary indicator based on values of a1200
# Set to 1 if a1200 is in the set {1, 2, 4, 5, 6}, otherwise 0
InsV_2 <- ifelse(ecf_2016$a1200 %in% c(1, 2, 4, 5, 6), 1, 0)

df <- data.frame(
  
  InsV_1 = InsV_1,
  InsV_2 = InsV_2,
  Filter = ecf_2016$b0600
  
)

df <- df[df$Filter != -98, ]

InsV_1 <- df$InsV_1
InsV_2 <- df$InsV_2

# Clean memory
rm(df)

################################################################################
### REGRESSION
################################################################################

# This R script performs an Instrumental Variable (IV) Regression for Model 1 using 
# the ivreg() function from the AER package. The model is designed to estimate the 
# effect of an endogenous independent variable on a dependent variable while controlling 
# for potential endogeneity through the use of an instrumental variable.


# MODEL 1.1 (IVar: Cultural Level)
data <- data.frame(
  Y = DV1,                 # Dependent variable
  X = IV,                  # Endogenous independent variable
  Z = InsV_1,              # Instrumental variable
  C_1 = I1,                # Control variable 1
  C_2 = I2,                # Control variable 2
  C_3 = I3,                # Control variable 3
  C_4 = I4                 # Control variable 4  
)

fitY.LX <- glm(formula = Y ~ X + C_1 + C_2 + C_3 + C_4, family = "binomial", data = data)
fitX.LZ <- glm(formula = X ~ Z + C_1 + C_2 + C_3 + C_4, data = data)
fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data = data)
summary(fitIV_ts)

# Call:  
#  ivglm(estmethod = "ts", fitX.LZ = fitX.LZ, fitY.LX = fitY.LX, data = data)
#
# Coefficients: 
#  Estimate Std. Error z value Pr(>|z|)    
#  (Intercept)  -2.3255     0.5636  -4.126 3.69e-05 ***
#  X             1.9480     0.8915   2.185   0.0289 *  
#  C_1           1.2321     0.2996   4.113 3.91e-05 ***
#  C_2          -0.0165     0.3212  -0.051   0.9590    
#  C_3           1.0987     0.2581   4.257 2.07e-05 ***
#  C_4          -1.4137     0.3489  -4.052 5.08e-05 ***
#  ---
#  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# MODEL 1.2 (IVar: Mathematical baggage) 
data <- data.frame(
  Y = DV1,                 # Dependent variable
  X = IV,                  # Endogenous independent variable
  Z = InsV_2,              # Instrumental variable
  C_1 = I1,                # Control variable 1
  C_2 = I2,                # Control variable 2
  C_3 = I3,                # Control variable 3
  C_4 = I4                 # Control variable 4  
)

fitY.LX <- glm(formula = Y ~ X + C_1 + C_2 + C_3 + C_4, family = "binomial", data = data)
fitX.LZ <- glm(formula = X ~ Z + C_1 + C_2 + C_3 + C_4, data = data)
fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data = data)
summary(fitIV_ts)

# Call:  
#  ivglm(estmethod = "ts", fitX.LZ = fitX.LZ, fitY.LX = fitY.LX,data = data)
#
# Coefficients: 
#  Estimate Std. Error z value Pr(>|z|)    
#  (Intercept)  -2.3295     0.4620  -5.043 4.59e-07 ***
#  X             1.9557     0.6221   3.144  0.00167 ** 
#  C_1           1.2314     0.2716   4.534 5.78e-06 ***
#  C_2          -0.0200     0.2968  -0.067  0.94627    
#  C_3           1.1044     0.2570   4.297 1.73e-05 ***
#  C_4          -1.4176     0.3442  -4.119 3.81e-05 ***
#  ---
#  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

