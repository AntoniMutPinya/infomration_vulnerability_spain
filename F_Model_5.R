

### DATA & PACKAGES

source('A_Data_&_Packages.R')

################################################################################
### INDEPENDENT VARIABLE (X)
################################################################################

# Calculate the Information Vulnerability Index (IV) using data related to financial literacy, basic numeracy,
# and graph reading skills. This index is estimated using an Item Response Theory (IRT) model.

# Min-Max scaling function for normalization
min_max_scale <- function(x) {
  min_range <- 0
  max_range <- 1
  min_x <- min(x)
  max_x <- max(x)
  min_range + ((x - min_x) / (max_x - min_x)) * (max_range - min_range)
}

# Function to create the answers dataframe used for IRT-based index calculation
create_df_Answers <- function(ecf_2016) {
  
  # Dataframe creation using conditional logic for Financial Literacy (FL), Numeracy (NL), and Graph Reading
  df_Answers <- data.frame(
    
    # Financial Literacy questions
    FL1 = ifelse(ecf_2016$e0600 == 3, 1, 0),
    FL2 = ifelse(ecf_2016$e0700 == 0, 1, 0),
    FL3 = ifelse(ecf_2016$e0800 == 102, 1, 0),
    FL4 = ifelse(ecf_2016$e0900 == 1, 1, 0),
    FL5 = ifelse(ecf_2016$e1001 == 1, 1, 0),
    FL6 = ifelse(ecf_2016$e1002 == 1, 1, 0),
    FL7 = ifelse(ecf_2016$e1003 == 1, 1, 0),
    FL8 = ifelse(ecf_2016$e1200 == 1, 1, 0),
    
    # Basic Numeracy and Literacy
    NL1 = ifelse(ecf_2016$e0500 == 200, 1, 0),
    NL2 = ifelse(ecf_2016$e1101 == 1, 1, 0),
    NL3 = ifelse(ecf_2016$e1102 == 3, 1, 0),
    NL4 = ifelse(ecf_2016$e0401 == 3, 1, 0),
    NL5 = ifelse(ecf_2016$e0402 == 18, 1, 0),
    NL6 = ifelse(ecf_2016$e0403 == 2, 1, 0),
    NL7 = ifelse(ecf_2016$e0300 == 5, 1, 0),
    
    # Reading Graphs (each correct answer contributes to the score)
    e0200a = ifelse(ecf_2016$e0200a == 1, 0.2, 0),
    e0200b = ifelse(ecf_2016$e0200b == 1, 0.2, 0),
    e0200c = ifelse(ecf_2016$e0200c == 0, 0.2, 0),
    e0200d = ifelse(ecf_2016$e0200d == 0, 0.2, 0),
    e0200e = ifelse(ecf_2016$e0200e == 0, 0.2, 0),
    
    # Filter variable
    filter = ecf_2016$b0600
  )
  
  # Sum graph reading questions to create an overall score
  df_Answers$NL8 <- df_Answers$e0200a + df_Answers$e0200b + df_Answers$e0200c + 
    df_Answers$e0200d + df_Answers$e0200e
  
  # Remove unnecessary columns
  df_Answers <- df_Answers[, !colnames(df_Answers) %in% c("e0200a", "e0200b", "e0200c", "e0200d", "e0200e")]
  
  # Filter out invalid data (-98 values)
  df_Answers <- df_Answers[df_Answers$filter != -98, ]
  return(df_Answers)
}

# Function to fit a 2PL model and calculate the Information Vulnerability Index
create_index <- function(df_Answers, unimodel = 'F1 = 1-16') {
  
  # Select financial literacy and numeracy columns
  columns_FL <- grep("^FL|NL", names(df_Answers), value = TRUE)
  df_FL <- df_Answers[, columns_FL]
  
  # Fit the 2PL IRT model
  fit2PL <- mirt(data = df_FL, model = unimodel, itemtype = "2PL", verbose = FALSE)
  
  # Extract the factor scores (theta) as the index
  IV <- fscores(fit2PL)
  
  return(IV)
}

# Generate the IV index
df_Answers <- create_df_Answers(ecf_2016)
IV <- min_max_scale(create_index(df_Answers))
IV <- as.data.frame(IV)
IV <- IV$F1

# Clean up variables
rm(df_Answers, create_df_Answers, create_index)

################################################################################
### DEPENDENT VARIABLE (Y)
################################################################################

# Calculate DV5: Handle missing values in b0700b by replacing negative values with NaN

DV5 <- ifelse(ecf_2016$b0700c == -98, NA, ifelse(ecf_2016$b0700c > 0, 1, 0))
DV5 <- na.omit(DV5)

################################################################################
### CONTROL VARIABLES (PCA)
################################################################################

# Perform PCA on selected sociodemographic variables and generate 4 components (I1, I2, I3, I4) as control variables.

# Create the dataset for PCA analysis
BE <- data.frame(
  Filter = ecf_2016$b0600,
  Q1 = ifelse(ecf_2016$d0101 > 0, ecf_2016$d0101, 0),
  Q2 = ifelse(ecf_2016$d0102 > 0, ecf_2016$d0102, 0),
  Q3 = ifelse(ecf_2016$d0103 > 0, ecf_2016$d0103, 0),
  Q4 = ifelse(ecf_2016$d0104 > 0, ecf_2016$d0104, 0),
  Q5 = ifelse(ecf_2016$d0105 > 0, ecf_2016$d0105, 0),
  Q6 = ifelse(ecf_2016$d0106 > 0, ecf_2016$d0106, 0),
  Q7 = ifelse(ecf_2016$d0107 > 0, ecf_2016$d0107, 0),
  Q8 = ifelse(ecf_2016$d0108 > 0, ecf_2016$d0108, 0),
  Q9 = ifelse(ecf_2016$d0109 > 0, ecf_2016$d0109, 0),
  Q10 = ifelse(ecf_2016$d0110 > 0, ecf_2016$d0110, 0),
  Q11 = ifelse(ecf_2016$d0111 > 0, ecf_2016$d0111, 0),
  Q12 = ifelse(ecf_2016$d0112 > 0, ecf_2016$d0112, 0)
)

# Remove invalid data
BE <- BE[BE$Filter != -98, ]

# Perform PCA analysis and extract 4 components
mat_cor <- hetcor(BE)$correlations  # Correlation matrix
fa_FL <- fa(BE, nfactors = 4, rotate = 'none', fm = 'pa', max.iter = 1, scores = "Bartlett")
df_Inst <- as.data.frame(fa_FL$scores)

# Apply Min-Max scaling to the factor scores
I1 <- min_max_scale(df_Inst$PA1)
I2 <- min_max_scale(df_Inst$PA2)
I3 <- min_max_scale(df_Inst$PA3)
I4 <- min_max_scale(df_Inst$PA4)

# Clean memory
rm(fa_FL, mat_cor, df_Inst, BE)

################################################################################
### INSTRUMENTAL VARIABLES
################################################################################

# Create the instrumental variables to address potential endogeneity in regression models.

# IV_1: Binary indicator based on the number of books in childhood (a1400 >= 4)
InsV_1 <- ifelse(ecf_2016$a1400 >= 4, 1, 0)

# IV_2: Binary indicator for specific university qualifications requiring mathematical or financial knowledge
InsV_2 <- ifelse(ecf_2016$a1200 %in% c(1, 2, 4, 5, 6), 1, 0)

df <- data.frame(  
  InsV_1 = InsV_1,
  InsV_2 = InsV_2,
  Filter = ecf_2016$b0600
)

df <- df[df$Filter != -98, ]

InsV_1 <- df$InsV_1
InsV_2 <- df$InsV_2

# Clean memory
rm(df)

################################################################################
### REGRESSION (IV Models)
################################################################################

# Perform Instrumental Variable (IV) regression to estimate the effect of the endogenous independent variable on the dependent variable.

# Model 5.1: Using Instrumental Variable 1 (Cultural Level)
data <- data.frame(
  Y = DV5,
  X = IV,
  Z = InsV_1,
  C_1 = I1,
  C_2 = I2,
  C_3 = I3,
  C_4 = I4
)

fitY.LX <- glm(Y ~ X + C_1 + C_2 + C_3 + C_4, family = "binomial", data = data)
fitX.LZ <- glm(X ~ Z, data = data)
fitIV_ts <- ivglm(estmethod = "ts", fitX.LZ = fitX.LZ, fitY.LX = fitY.LX, data = data)
summary(fitIV_ts)


# Model 5.2: Using Instrumental Variable 2 (Mathematical Baggage)
data <- data.frame(
  Y = DV5,                 # Dependent variable
  X = IV,                  # Endogenous independent variable
  Z = InsV_2,              # Instrumental variable
  C_1 = I1,                # Control variable 1
  C_2 = I2,                # Control variable 2
  C_3 = I3,                # Control variable 3
  C_4 = I4                 # Control variable 4  
)

fitY.LX <- glm(formula = Y ~ X + C_1 + C_2 + C_3 + C_4, family = "binomial", data = data)
fitX.LZ <- glm(formula = X ~ Z + C_1 + C_2 + C_3 + C_4, data = data)
fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data = data)
summary(fitIV_ts)
