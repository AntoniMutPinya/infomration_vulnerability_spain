
### DATA & PACKAGES

source('A_Data_&_Packages.R')

################################################################################
### INDEPENDENT VARIABLE (X)
################################################################################

# Calculate the Information Vulnerability Index (IV) using data related to financial literacy, basic numeracy,
# and graph reading skills. This index is estimated using an Item Response Theory (IRT) model.

# Min-Max scaling function for normalization
min_max_scale <- function(x) {
  min_range <- 0
  max_range <- 1
  min_x <- min(x)
  max_x <- max(x)
  min_range + ((x - min_x) / (max_x - min_x)) * (max_range - min_range)
}

# Function to create the answers dataframe used for IRT-based index calculation
create_df_Answers <- function(ecf_2016) {
  
  # Dataframe creation using conditional logic for Financial Literacy (FL), Numeracy (NL), and Graph Reading
  df_Answers <- data.frame(
    
    # Financial Literacy questions
    FL1 = ifelse(ecf_2016$e0600 == 3, 1, 0),
    FL2 = ifelse(ecf_2016$e0700 == 0, 1, 0),
    FL3 = ifelse(ecf_2016$e0800 == 102, 1, 0),
    FL4 = ifelse(ecf_2016$e0900 == 1, 1, 0),
    FL5 = ifelse(ecf_2016$e1001 == 1, 1, 0),
    FL6 = ifelse(ecf_2016$e1002 == 1, 1, 0),
    FL7 = ifelse(ecf_2016$e1003 == 1, 1, 0),
    FL8 = ifelse(ecf_2016$e1200 == 1, 1, 0),
    
    # Basic Numeracy and Literacy
    NL1 = ifelse(ecf_2016$e0500 == 200, 1, 0),
    NL2 = ifelse(ecf_2016$e1101 == 1, 1, 0),
    NL3 = ifelse(ecf_2016$e1102 == 3, 1, 0),
    NL4 = ifelse(ecf_2016$e0401 == 3, 1, 0),
    NL5 = ifelse(ecf_2016$e0402 == 18, 1, 0),
    NL6 = ifelse(ecf_2016$e0403 == 2, 1, 0),
    NL7 = ifelse(ecf_2016$e0300 == 5, 1, 0),
    
    # Reading Graphs (each correct answer contributes to the score)
    e0200a = ifelse(ecf_2016$e0200a == 1, 0.2, 0),
    e0200b = ifelse(ecf_2016$e0200b == 1, 0.2, 0),
    e0200c = ifelse(ecf_2016$e0200c == 0, 0.2, 0),
    e0200d = ifelse(ecf_2016$e0200d == 0, 0.2, 0),
    e0200e = ifelse(ecf_2016$e0200e == 0, 0.2, 0),
    
    # Filter variable
    filter = ecf_2016$b0600
  )
  
  # Sum graph reading questions to create an overall score
  df_Answers$NL8 <- df_Answers$e0200a + df_Answers$e0200b + df_Answers$e0200c + 
    df_Answers$e0200d + df_Answers$e0200e
  
  # Remove unnecessary columns
  df_Answers <- df_Answers[, !colnames(df_Answers) %in% c("e0200a", "e0200b", "e0200c", "e0200d", "e0200e")]
  
  # Filter out invalid data (-98 values)
  df_Answers <- df_Answers[df_Answers$filter != -98, ]
  return(df_Answers)
}

# Function to fit a 2PL model and calculate the Information Vulnerability Index
create_index <- function(df_Answers, unimodel = 'F1 = 1-16') {
  
  # Select financial literacy and numeracy columns
  columns_FL <- grep("^FL|NL", names(df_Answers), value = TRUE)
  df_FL <- df_Answers[, columns_FL]
  
  # Fit the 2PL IRT model
  fit2PL <- mirt(data = df_FL, model = unimodel, itemtype = "2PL", verbose = FALSE)
  
  # Extract the factor scores (theta) as the index
  IV <- fscores(fit2PL)
  
  return(IV)
}

# Generate the IV index
df_Answers <- create_df_Answers(ecf_2016)
IV <- min_max_scale(create_index(df_Answers))
IV <- as.data.frame(IV)
IV <- IV$F1

# Clean up variables
rm(df_Answers, create_df_Answers, create_index)

################################################################################
### DEPENDENT VARIABLE (Y)
################################################################################

# Select specific columns (b0700b to b0700r) from ecf_2016 and store in df
df <- ecf_2016 %>% dplyr::select(b0700b, b0700c, b0700d, b0700e, b0700f, b0700g, 
                                 b0700h, b0700i, b0700a, b0700m, b0700n, b0700o, 
                                 b0700p, b0700q, b0700r)

# Apply binary transformation for columns b0700b to b0700i
# If the value is negative, set it to NA (missing); if greater than 0, set it to 1, otherwise 0
df$b0700b <- ifelse(df$b0700b == -98, NA, ifelse(df$b0700b > 0, 1, 0))
df$b0700c <- ifelse(df$b0700c == -98, NA, ifelse(df$b0700c > 0, 1, 0))
df$b0700d <- ifelse(df$b0700d == -98, NA, ifelse(df$b0700d > 0, 1, 0))
df$b0700e <- ifelse(df$b0700e == -98, NA, ifelse(df$b0700e > 0, 1, 0))
df$b0700f <- ifelse(df$b0700f == -98, NA, ifelse(df$b0700f > 0, 1, 0))
df$b0700g <- ifelse(df$b0700g == -98, NA, ifelse(df$b0700g > 0, 1, 0))
df$b0700h <- ifelse(df$b0700h == -98, NA, ifelse(df$b0700h > 0, 1, 0))
df$b0700i <- ifelse(df$b0700i == -98, NA, ifelse(df$b0700i > 0, 1, 0))

# Apply transformation for columns b0700a to b0700r
# If the value is negative, set it to NA; if greater than 0, set it to -1, otherwise 0
df$b0700a <- ifelse(df$b0700a == -98, NA, ifelse(df$b0700a > 0, -1, 0))
df$b0700m <- ifelse(df$b0700m == -98, NA, ifelse(df$b0700m > 0, -1, 0))
df$b0700n <- ifelse(df$b0700n == -98, NA, ifelse(df$b0700n > 0, -1, 0))
df$b0700o <- ifelse(df$b0700o == -98, NA, ifelse(df$b0700o > 0, -1, 0))
df$b0700p <- ifelse(df$b0700p == -98, NA, ifelse(df$b0700p > 0, -1, 0))
df$b0700q <- ifelse(df$b0700q == -98, NA, ifelse(df$b0700q > 0, -1, 0))
df$b0700r <- ifelse(df$b0700r == -98, NA, ifelse(df$b0700r > 0, -1, 0))

# Create two new columns summing binary variables
# Fuentes_OK: Sum of columns b0700b to b0700i (positive variables)
df$Fuentes_OK <- df$b0700b + df$b0700c + df$b0700d + df$b0700e + df$b0700f + 
  df$b0700g + df$b0700h + df$b0700i

# Fuentes_No_OK: Sum of columns b0700a to b0700r (negative variables)
df$Fuentes_No_OK <- df$b0700a + df$b0700m + df$b0700n + df$b0700o + df$b0700p + 
  df$b0700q + df$b0700r 

# Select the two calculated columns into a new dataframe df_DV_b
df_DV_b <- df %>% select(Fuentes_OK, Fuentes_No_OK)

# Calculate DV3: Fuentes_OK minus Fuentes_No_OK, set values greater than 1 to 1, others to 0
DV3 <- df_DV_b$Fuentes_OK + df_DV_b$Fuentes_No_OK*-1
DV3 <- ifelse(DV3 > 1, 1, 0)
DV3 <- na.omit(DV3)

rm(df_DV_b)

################################################################################
### CONTROL VARIABLES (PCA)
################################################################################

# Perform PCA on selected sociodemographic variables and generate 4 components (I1, I2, I3, I4) as control variables.

# Create the dataset for PCA analysis
BE <- data.frame(
  Filter = ecf_2016$b0600,
  Q1 = ifelse(ecf_2016$d0101 > 0, ecf_2016$d0101, 0),
  Q2 = ifelse(ecf_2016$d0102 > 0, ecf_2016$d0102, 0),
  Q3 = ifelse(ecf_2016$d0103 > 0, ecf_2016$d0103, 0),
  Q4 = ifelse(ecf_2016$d0104 > 0, ecf_2016$d0104, 0),
  Q5 = ifelse(ecf_2016$d0105 > 0, ecf_2016$d0105, 0),
  Q6 = ifelse(ecf_2016$d0106 > 0, ecf_2016$d0106, 0),
  Q7 = ifelse(ecf_2016$d0107 > 0, ecf_2016$d0107, 0),
  Q8 = ifelse(ecf_2016$d0108 > 0, ecf_2016$d0108, 0),
  Q9 = ifelse(ecf_2016$d0109 > 0, ecf_2016$d0109, 0),
  Q10 = ifelse(ecf_2016$d0110 > 0, ecf_2016$d0110, 0),
  Q11 = ifelse(ecf_2016$d0111 > 0, ecf_2016$d0111, 0),
  Q12 = ifelse(ecf_2016$d0112 > 0, ecf_2016$d0112, 0)
)

# Remove invalid data
BE <- BE[BE$Filter != -98, ]

# Perform PCA analysis and extract 4 components
mat_cor <- hetcor(BE)$correlations  # Correlation matrix
fa_FL <- fa(BE, nfactors = 4, rotate = 'none', fm = 'pa', max.iter = 1, scores = "Bartlett")
df_Inst <- as.data.frame(fa_FL$scores)

# Apply Min-Max scaling to the factor scores
I1 <- min_max_scale(df_Inst$PA1)
I2 <- min_max_scale(df_Inst$PA2)
I3 <- min_max_scale(df_Inst$PA3)
I4 <- min_max_scale(df_Inst$PA4)

# Clean memory
rm(fa_FL, mat_cor, df_Inst, BE)

################################################################################
### INSTRUMENTAL VARIABLES
################################################################################

# Create the instrumental variables to address potential endogeneity in regression models.

# IV_1: Binary indicator based on the number of books in childhood (a1400 >= 4)
InsV_1 <- ifelse(ecf_2016$a1400 >= 4, 1, 0)

# IV_2: Binary indicator for specific university qualifications requiring mathematical or financial knowledge
InsV_2 <- ifelse(ecf_2016$a1200 %in% c(1, 2, 4, 5, 6), 1, 0)

df <- data.frame(  
  InsV_1 = InsV_1,
  InsV_2 = InsV_2,
  Filter = ecf_2016$b0600
)

df <- df[df$Filter != -98, ]

InsV_1 <- df$InsV_1
InsV_2 <- df$InsV_2

# Clean memory
rm(df)

################################################################################
### REGRESSION (IV Models)
################################################################################

# Perform Instrumental Variable (IV) regression to estimate the effect of the endogenous independent variable on the dependent variable.

# Model 3.1: Using Instrumental Variable 1 (Cultural Level)
data <- data.frame(
  Y = DV3,
  X = IV,
  Z = InsV_1,
  C_1 = I1,
  C_2 = I2,
  C_3 = I3,
  C_4 = I4
)

fitY.LX <- glm(Y ~ X + C_1 + C_2 + C_3 + C_4, family = "binomial", data = data)
fitX.LZ <- glm(X ~ Z + C_1 + C_2 + C_3 + C_4, data = data)
fitIV_ts <- ivglm(estmethod = "ts", fitX.LZ = fitX.LZ, fitY.LX = fitY.LX, data = data)
# summary(fitIV_ts)

# Call:  
#  ivglm(estmethod = "ts", fitX.LZ = fitX.LZ, fitY.LX = fitY.LX, data = data)
#
# Coefficients: 
#  Estimate Std. Error z value Pr(>|z|)    
#  (Intercept)  -3.3867     0.6221  -5.444 5.21e-08 ***
#  X             2.1507     0.9758   2.204   0.0275 *  
#  C_1           0.6858     0.3238   2.118   0.0342 *  
#  C_2           0.2687     0.3590   0.748   0.4543    
#  C_3           0.6393     0.2750   2.325   0.0201 *  
#  C_4          -0.1821     0.3883  -0.469   0.6391    
#  ---
#  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# Model 3.2: Using Instrumental Variable 2 (Mathematical Baggage)
data <- data.frame(
  Y = DV3,                 # Dependent variable
  X = IV,                  # Endogenous independent variable
  Z = InsV_2,              # Instrumental variable
  C_1 = I1,                # Control variable 1
  C_2 = I2,                # Control variable 2
  C_3 = I3,                # Control variable 3
  C_4 = I4                 # Control variable 4  
)

fitY.LX <- glm(formula = Y ~ X + C_1 + C_2 + C_3 + C_4, family = "binomial", data = data)
fitX.LZ <- glm(formula = X ~ Z + C_1 + C_2 + C_3 + C_4, data = data)
fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data = data)
# summary(fitIV_ts)

# Call:  
#  ivglm(estmethod = "ts", fitX.LZ = fitX.LZ, fitY.LX = fitY.LX, data = data)
#
# Coefficients: 
#  Estimate Std. Error z value Pr(>|z|)    
# (Intercept)  -3.3958     0.5065  -6.705 2.02e-11 ***
# X             2.1690     0.6735   3.221  0.00128 ** 
# C_1           0.6789     0.2986   2.274  0.02299 *  
# C_2           0.2612     0.3298   0.792  0.42829    
# C_3           0.6461     0.2739   2.359  0.01832 *  
# C_4          -0.1818     0.3846  -0.473  0.63640    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


